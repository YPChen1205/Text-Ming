{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home assignment 2\n",
    "\n",
    "You should work on the assignement in groups/teams of 3 participants. Submissions of single students will not be accepted! Please use the Forum in case of doubt in order to find team mates!\n",
    "\n",
    "Upload your solution as a jupyter notebook to moodle by Tuesday, 7th of January 23:55h. (The deadline is strict)\n",
    "It is sufficient if one student of each team submits the solution.\n",
    "\n",
    "\n",
    "You should add comments to your code where necessary and print the relevant results. You should also always test your code on self-chosen examples.\n",
    "\n",
    "Do not forget to specify the (First_name, Last_name, student_id (matrikelnummer)) of all contributing students in the jupyter notebook here:\n",
    "\n",
    "Student 1: `Yaping, Chen, 379645`\n",
    "\n",
    "Student 2: `First_name, Last_name, student_id`\n",
    "\n",
    "Student 3: `First_name, Last_name, student_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing GloVe\n",
    "In this task you will implement the glove algorithm using PyTorch. (One advantage is that you need not calculate gradient by hand, but you can take advantage of the autograd module). The task will require implementation of certain functions, which we look into step-by-step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for word to index mapping. Since the model won't be able to take strings as input we will convert them into indices. The function will generate a mapping  w2i which uses words as keys and corresponding indices as values e.g., `w2i['walk'] = 42`. As Preprocessing, remove all punctuations and convert all words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2indexMapping(textfile):\n",
    "    w2i = {}\n",
    "    text = [] # sequence of words as they appear in the text after removing punctuations\n",
    "    # write your code snippet here....\n",
    "    \n",
    "    \n",
    "    return w2i, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for calculating a two dimensional matrix $X_{ij}$ which is the number of times word $j$ occurred in the context of word $i$. The size of the context window $k$ (as a number of words, $k=2$ describes that the context contains the two words before and the two words after the central word) is also an argument of the function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrenceFreq(text, w2i, k): # text is a sequence of words ordered as they appear in the text\n",
    "    # note that there is no notion of sentence here...\n",
    "    \n",
    "    X_ij =  np.zeros((len(w2i), len(w2i)))\n",
    "    # write your code snippet here...\n",
    "    \n",
    "    \n",
    "    return X_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a GloVe model class with parameters $w$, $\\hat w$, $b$ and $\\hat b$. For a particular pair of words $i$, $j$, your forward function should implement $w_{i}^{T}\\hat w_{j} + b_{i} + \\hat b_{j}$. Assume a dimension of embedding to be $d$ which you will specify when creating an instance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Glove(nn.Module):\n",
    "    \n",
    "    # write your model class here....\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that implements the weighting function $f(X_{ij})$\n",
    "\n",
    "$f(x) = (\\frac{x}{100})^{\\frac{3}{4}}$ if x<100 \n",
    "\n",
    "$f(x) = 1 $ otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightFunction(X_ij, i, j):\n",
    "    f = 0\n",
    "    \n",
    "    # write your code snippet here\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a train function to train the model using stochastic gradient descent. Your each training instance would be a word-context pair ($i$, $j$) and the corresponding loss function would be \n",
    "\n",
    "$f(X_{ij})(w_{i}^{T}\\hat w_{j} + b_{i} + \\hat b_{j} - log(1 + X_{ij}))^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_ij, learning_rate=0.001, epochs=5):\n",
    "    optimizer = # use Adam as your optimizer\n",
    "    for _ in epochs:\n",
    "        # train across each word-conext pair\n",
    "        # calculate loss\n",
    "        # backpropagate for every training example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to generate embeddings given a word. The embedding of a word with index $i$ would $w_i + \\hat w_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbedding(model, word):\n",
    "    # write your code snippet here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the individual components together to train a Glove model from the given text file  'shakespeare-caesar.txt' with dimension 200 and a context window of 5.\n",
    "Manually inspect nearest neigbors for some self-picked words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings with gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim is a package which allows you to train word embeddings as well. The task is to take a text file (like 'shakespeare-caesar.txt') and generate embeddings of the vocabulary. You can consult the documentation here - \n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color= red>Missing separating punctuations or a better way to read txt as corpus?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'of': <gensim.models.keyedvectors.Vocab at 0x25e63124808>,\n",
       " 'caesar': <gensim.models.keyedvectors.Vocab at 0x25e63124848>,\n",
       " 'by': <gensim.models.keyedvectors.Vocab at 0x25e63124888>,\n",
       " 'actus': <gensim.models.keyedvectors.Vocab at 0x25e631248c8>,\n",
       " 'enter': <gensim.models.keyedvectors.Vocab at 0x25e63124e08>,\n",
       " 'and': <gensim.models.keyedvectors.Vocab at 0x25e63124e88>,\n",
       " 'ouer': <gensim.models.keyedvectors.Vocab at 0x25e63124ec8>,\n",
       " 'the': <gensim.models.keyedvectors.Vocab at 0x25e63124f08>,\n",
       " 'home': <gensim.models.keyedvectors.Vocab at 0x25e63124dc8>,\n",
       " 'you': <gensim.models.keyedvectors.Vocab at 0x25e63124e48>,\n",
       " 'get': <gensim.models.keyedvectors.Vocab at 0x25e63124f48>,\n",
       " 'is': <gensim.models.keyedvectors.Vocab at 0x25e63124f88>,\n",
       " 'this': <gensim.models.keyedvectors.Vocab at 0x25e63124fc8>,\n",
       " 'a': <gensim.models.keyedvectors.Vocab at 0x25e63127048>,\n",
       " 'what,': <gensim.models.keyedvectors.Vocab at 0x25e63127088>,\n",
       " 'know': <gensim.models.keyedvectors.Vocab at 0x25e631270c8>,\n",
       " 'not': <gensim.models.keyedvectors.Vocab at 0x25e63127108>,\n",
       " 'walke': <gensim.models.keyedvectors.Vocab at 0x25e63127148>,\n",
       " 'vpon': <gensim.models.keyedvectors.Vocab at 0x25e63127188>,\n",
       " 'day,': <gensim.models.keyedvectors.Vocab at 0x25e631271c8>,\n",
       " 'without': <gensim.models.keyedvectors.Vocab at 0x25e63127208>,\n",
       " 'your': <gensim.models.keyedvectors.Vocab at 0x25e63127248>,\n",
       " 'speake,': <gensim.models.keyedvectors.Vocab at 0x25e63127288>,\n",
       " 'what': <gensim.models.keyedvectors.Vocab at 0x25e631272c8>,\n",
       " 'trade': <gensim.models.keyedvectors.Vocab at 0x25e63127308>,\n",
       " 'art': <gensim.models.keyedvectors.Vocab at 0x25e63127348>,\n",
       " 'why': <gensim.models.keyedvectors.Vocab at 0x25e63127388>,\n",
       " 'sir,': <gensim.models.keyedvectors.Vocab at 0x25e631273c8>,\n",
       " 'mur.': <gensim.models.keyedvectors.Vocab at 0x25e63127408>,\n",
       " 'where': <gensim.models.keyedvectors.Vocab at 0x25e63127448>,\n",
       " 'thy': <gensim.models.keyedvectors.Vocab at 0x25e63127488>,\n",
       " 'thou': <gensim.models.keyedvectors.Vocab at 0x25e631274c8>,\n",
       " 'with': <gensim.models.keyedvectors.Vocab at 0x25e63127508>,\n",
       " 'best': <gensim.models.keyedvectors.Vocab at 0x25e63127548>,\n",
       " 'are': <gensim.models.keyedvectors.Vocab at 0x25e63127588>,\n",
       " 'you?': <gensim.models.keyedvectors.Vocab at 0x25e631275c8>,\n",
       " 'in': <gensim.models.keyedvectors.Vocab at 0x25e63127608>,\n",
       " 'respect': <gensim.models.keyedvectors.Vocab at 0x25e63127648>,\n",
       " 'i': <gensim.models.keyedvectors.Vocab at 0x25e63127688>,\n",
       " 'am': <gensim.models.keyedvectors.Vocab at 0x25e631276c8>,\n",
       " 'but': <gensim.models.keyedvectors.Vocab at 0x25e63127708>,\n",
       " 'as': <gensim.models.keyedvectors.Vocab at 0x25e63127748>,\n",
       " 'would': <gensim.models.keyedvectors.Vocab at 0x25e63127788>,\n",
       " 'say,': <gensim.models.keyedvectors.Vocab at 0x25e631277c8>,\n",
       " 'answer': <gensim.models.keyedvectors.Vocab at 0x25e63127808>,\n",
       " 'me': <gensim.models.keyedvectors.Vocab at 0x25e63127848>,\n",
       " 'directly': <gensim.models.keyedvectors.Vocab at 0x25e63127888>,\n",
       " 'that': <gensim.models.keyedvectors.Vocab at 0x25e631278c8>,\n",
       " 'may': <gensim.models.keyedvectors.Vocab at 0x25e63127908>,\n",
       " 'vse,': <gensim.models.keyedvectors.Vocab at 0x25e63127948>,\n",
       " 'which': <gensim.models.keyedvectors.Vocab at 0x25e63127988>,\n",
       " 'bad': <gensim.models.keyedvectors.Vocab at 0x25e631279c8>,\n",
       " 'fla.': <gensim.models.keyedvectors.Vocab at 0x25e63127a08>,\n",
       " 'be': <gensim.models.keyedvectors.Vocab at 0x25e63127a48>,\n",
       " 'out': <gensim.models.keyedvectors.Vocab at 0x25e63127a88>,\n",
       " 'me:': <gensim.models.keyedvectors.Vocab at 0x25e63127ac8>,\n",
       " 'yet': <gensim.models.keyedvectors.Vocab at 0x25e63127b08>,\n",
       " 'if': <gensim.models.keyedvectors.Vocab at 0x25e63127b48>,\n",
       " 'can': <gensim.models.keyedvectors.Vocab at 0x25e63127b88>,\n",
       " 'all': <gensim.models.keyedvectors.Vocab at 0x25e63127bc8>,\n",
       " 'liue': <gensim.models.keyedvectors.Vocab at 0x25e63127c08>,\n",
       " 'by,': <gensim.models.keyedvectors.Vocab at 0x25e63127c48>,\n",
       " 'no': <gensim.models.keyedvectors.Vocab at 0x25e63127c88>,\n",
       " 'nor': <gensim.models.keyedvectors.Vocab at 0x25e63127cc8>,\n",
       " 'to': <gensim.models.keyedvectors.Vocab at 0x25e63127d08>,\n",
       " 'old': <gensim.models.keyedvectors.Vocab at 0x25e63127d48>,\n",
       " 'when': <gensim.models.keyedvectors.Vocab at 0x25e63127d88>,\n",
       " 'they': <gensim.models.keyedvectors.Vocab at 0x25e63127dc8>,\n",
       " 'great': <gensim.models.keyedvectors.Vocab at 0x25e63127e08>,\n",
       " 'them.': <gensim.models.keyedvectors.Vocab at 0x25e63127e48>,\n",
       " 'men': <gensim.models.keyedvectors.Vocab at 0x25e63127e88>,\n",
       " 'euer': <gensim.models.keyedvectors.Vocab at 0x25e63127ec8>,\n",
       " 'haue': <gensim.models.keyedvectors.Vocab at 0x25e63127f08>,\n",
       " 'my': <gensim.models.keyedvectors.Vocab at 0x25e63127f48>,\n",
       " 'wherefore': <gensim.models.keyedvectors.Vocab at 0x25e63127f88>,\n",
       " 'leade': <gensim.models.keyedvectors.Vocab at 0x25e63127fc8>,\n",
       " 'these': <gensim.models.keyedvectors.Vocab at 0x25e6312a048>,\n",
       " 'about': <gensim.models.keyedvectors.Vocab at 0x25e6312a088>,\n",
       " 'their': <gensim.models.keyedvectors.Vocab at 0x25e6312a0c8>,\n",
       " 'selfe': <gensim.models.keyedvectors.Vocab at 0x25e6312a108>,\n",
       " 'into': <gensim.models.keyedvectors.Vocab at 0x25e6312a148>,\n",
       " 'more': <gensim.models.keyedvectors.Vocab at 0x25e6312a188>,\n",
       " 'we': <gensim.models.keyedvectors.Vocab at 0x25e6312a1c8>,\n",
       " 'make': <gensim.models.keyedvectors.Vocab at 0x25e6312a208>,\n",
       " 'see': <gensim.models.keyedvectors.Vocab at 0x25e6312a248>,\n",
       " 'caesar,': <gensim.models.keyedvectors.Vocab at 0x25e6312a288>,\n",
       " 'his': <gensim.models.keyedvectors.Vocab at 0x25e6312a2c8>,\n",
       " 'he': <gensim.models.keyedvectors.Vocab at 0x25e6312a308>,\n",
       " 'follow': <gensim.models.keyedvectors.Vocab at 0x25e6312a348>,\n",
       " 'him': <gensim.models.keyedvectors.Vocab at 0x25e6312a388>,\n",
       " 'rome,': <gensim.models.keyedvectors.Vocab at 0x25e6312a3c8>,\n",
       " 'then': <gensim.models.keyedvectors.Vocab at 0x25e6312a408>,\n",
       " 'o': <gensim.models.keyedvectors.Vocab at 0x25e6312a448>,\n",
       " 'many': <gensim.models.keyedvectors.Vocab at 0x25e6312a488>,\n",
       " 'time': <gensim.models.keyedvectors.Vocab at 0x25e6312a4c8>,\n",
       " 'vp': <gensim.models.keyedvectors.Vocab at 0x25e6312a508>,\n",
       " 'there': <gensim.models.keyedvectors.Vocab at 0x25e6312a548>,\n",
       " 'passe': <gensim.models.keyedvectors.Vocab at 0x25e6312a588>,\n",
       " 'saw': <gensim.models.keyedvectors.Vocab at 0x25e6312a5c8>,\n",
       " 'made': <gensim.models.keyedvectors.Vocab at 0x25e6312a608>,\n",
       " 'an': <gensim.models.keyedvectors.Vocab at 0x25e6312a648>,\n",
       " 'her': <gensim.models.keyedvectors.Vocab at 0x25e6312a688>,\n",
       " 'heare': <gensim.models.keyedvectors.Vocab at 0x25e6312a6c8>,\n",
       " 'do': <gensim.models.keyedvectors.Vocab at 0x25e6312a708>,\n",
       " 'now': <gensim.models.keyedvectors.Vocab at 0x25e6312a748>,\n",
       " 'put': <gensim.models.keyedvectors.Vocab at 0x25e6312a788>,\n",
       " 'on': <gensim.models.keyedvectors.Vocab at 0x25e6312a7c8>,\n",
       " 'comes': <gensim.models.keyedvectors.Vocab at 0x25e6312a808>,\n",
       " 'pompeyes': <gensim.models.keyedvectors.Vocab at 0x25e6312a848>,\n",
       " 'fall': <gensim.models.keyedvectors.Vocab at 0x25e6312a888>,\n",
       " 'pray': <gensim.models.keyedvectors.Vocab at 0x25e6312a8c8>,\n",
       " 'gods': <gensim.models.keyedvectors.Vocab at 0x25e6312a908>,\n",
       " 'must': <gensim.models.keyedvectors.Vocab at 0x25e6312a948>,\n",
       " 'good': <gensim.models.keyedvectors.Vocab at 0x25e6312a988>,\n",
       " 'countrymen,': <gensim.models.keyedvectors.Vocab at 0x25e6312a9c8>,\n",
       " 'for': <gensim.models.keyedvectors.Vocab at 0x25e6312aa08>,\n",
       " 'poore': <gensim.models.keyedvectors.Vocab at 0x25e6312aa48>,\n",
       " 'them': <gensim.models.keyedvectors.Vocab at 0x25e6312aa88>,\n",
       " 'till': <gensim.models.keyedvectors.Vocab at 0x25e6312aac8>,\n",
       " 'most': <gensim.models.keyedvectors.Vocab at 0x25e6312ab08>,\n",
       " 'all.': <gensim.models.keyedvectors.Vocab at 0x25e6312ab48>,\n",
       " 'exeunt.': <gensim.models.keyedvectors.Vocab at 0x25e6312ab88>,\n",
       " 'go': <gensim.models.keyedvectors.Vocab at 0x25e6312abc8>,\n",
       " 'downe': <gensim.models.keyedvectors.Vocab at 0x25e6312ac08>,\n",
       " 'way': <gensim.models.keyedvectors.Vocab at 0x25e6312ac48>,\n",
       " 'will': <gensim.models.keyedvectors.Vocab at 0x25e6312ac88>,\n",
       " 'finde': <gensim.models.keyedvectors.Vocab at 0x25e6312acc8>,\n",
       " 'so?': <gensim.models.keyedvectors.Vocab at 0x25e6312ad08>,\n",
       " 'it': <gensim.models.keyedvectors.Vocab at 0x25e6312ad48>,\n",
       " 'matter,': <gensim.models.keyedvectors.Vocab at 0x25e6312ad88>,\n",
       " 'let': <gensim.models.keyedvectors.Vocab at 0x25e6312adc8>,\n",
       " 'caesars': <gensim.models.keyedvectors.Vocab at 0x25e6312ae08>,\n",
       " 'ile': <gensim.models.keyedvectors.Vocab at 0x25e6312ae48>,\n",
       " 'away': <gensim.models.keyedvectors.Vocab at 0x25e6312ae88>,\n",
       " 'from': <gensim.models.keyedvectors.Vocab at 0x25e6312aec8>,\n",
       " 'so': <gensim.models.keyedvectors.Vocab at 0x25e6312af08>,\n",
       " 'perceiue': <gensim.models.keyedvectors.Vocab at 0x25e6312af48>,\n",
       " 'flye': <gensim.models.keyedvectors.Vocab at 0x25e6312af88>,\n",
       " 'who': <gensim.models.keyedvectors.Vocab at 0x25e6312afc8>,\n",
       " 'else': <gensim.models.keyedvectors.Vocab at 0x25e6312c048>,\n",
       " 'men,': <gensim.models.keyedvectors.Vocab at 0x25e6312c088>,\n",
       " 'keepe': <gensim.models.keyedvectors.Vocab at 0x25e6312c0c8>,\n",
       " 'vs': <gensim.models.keyedvectors.Vocab at 0x25e6312c108>,\n",
       " 'antony': <gensim.models.keyedvectors.Vocab at 0x25e6312c148>,\n",
       " 'brutus,': <gensim.models.keyedvectors.Vocab at 0x25e6312c188>,\n",
       " 'cassius,': <gensim.models.keyedvectors.Vocab at 0x25e6312c1c8>,\n",
       " 'caska,': <gensim.models.keyedvectors.Vocab at 0x25e6312c208>,\n",
       " 'after': <gensim.models.keyedvectors.Vocab at 0x25e6312c248>,\n",
       " 'caes.': <gensim.models.keyedvectors.Vocab at 0x25e6312c288>,\n",
       " 'cask.': <gensim.models.keyedvectors.Vocab at 0x25e6312c2c8>,\n",
       " 'peace': <gensim.models.keyedvectors.Vocab at 0x25e6312c308>,\n",
       " 'ho,': <gensim.models.keyedvectors.Vocab at 0x25e6312c348>,\n",
       " 'speakes': <gensim.models.keyedvectors.Vocab at 0x25e6312c388>,\n",
       " 'calp.': <gensim.models.keyedvectors.Vocab at 0x25e6312c3c8>,\n",
       " 'heere': <gensim.models.keyedvectors.Vocab at 0x25e6312c408>,\n",
       " 'lord': <gensim.models.keyedvectors.Vocab at 0x25e6312c448>,\n",
       " 'stand': <gensim.models.keyedvectors.Vocab at 0x25e6312c488>,\n",
       " 'doth': <gensim.models.keyedvectors.Vocab at 0x25e6312c4c8>,\n",
       " 'run': <gensim.models.keyedvectors.Vocab at 0x25e6312c508>,\n",
       " 'ant.': <gensim.models.keyedvectors.Vocab at 0x25e6312c548>,\n",
       " 'our': <gensim.models.keyedvectors.Vocab at 0x25e6312c588>,\n",
       " 'shake': <gensim.models.keyedvectors.Vocab at 0x25e6312c5c8>,\n",
       " 'off': <gensim.models.keyedvectors.Vocab at 0x25e6312c608>,\n",
       " 'shall': <gensim.models.keyedvectors.Vocab at 0x25e6312c648>,\n",
       " 'sayes,': <gensim.models.keyedvectors.Vocab at 0x25e6312c688>,\n",
       " 'set': <gensim.models.keyedvectors.Vocab at 0x25e6312c6c8>,\n",
       " 'on,': <gensim.models.keyedvectors.Vocab at 0x25e6312c708>,\n",
       " 'leaue': <gensim.models.keyedvectors.Vocab at 0x25e6312c748>,\n",
       " 'sooth.': <gensim.models.keyedvectors.Vocab at 0x25e6312c788>,\n",
       " 'bid': <gensim.models.keyedvectors.Vocab at 0x25e6312c7c8>,\n",
       " 'euery': <gensim.models.keyedvectors.Vocab at 0x25e6312c808>,\n",
       " 'me?': <gensim.models.keyedvectors.Vocab at 0x25e6312c848>,\n",
       " 'tongue': <gensim.models.keyedvectors.Vocab at 0x25e6312c888>,\n",
       " 'caesar:': <gensim.models.keyedvectors.Vocab at 0x25e6312c8c8>,\n",
       " 'ides': <gensim.models.keyedvectors.Vocab at 0x25e6312c908>,\n",
       " 'march': <gensim.models.keyedvectors.Vocab at 0x25e6312c948>,\n",
       " 'man': <gensim.models.keyedvectors.Vocab at 0x25e6312c988>,\n",
       " 'before': <gensim.models.keyedvectors.Vocab at 0x25e6312c9c8>,\n",
       " 'me,': <gensim.models.keyedvectors.Vocab at 0x25e6312ca08>,\n",
       " 'face': <gensim.models.keyedvectors.Vocab at 0x25e6312ca48>,\n",
       " 'cassi.': <gensim.models.keyedvectors.Vocab at 0x25e6312ca88>,\n",
       " 'fellow,': <gensim.models.keyedvectors.Vocab at 0x25e6312cac8>,\n",
       " 'come': <gensim.models.keyedvectors.Vocab at 0x25e6312cb08>,\n",
       " 'againe,': <gensim.models.keyedvectors.Vocab at 0x25e6312cb48>,\n",
       " 'him:': <gensim.models.keyedvectors.Vocab at 0x25e6312cb88>,\n",
       " 'brut.': <gensim.models.keyedvectors.Vocab at 0x25e6312cbc8>,\n",
       " '&': <gensim.models.keyedvectors.Vocab at 0x25e6312cc08>,\n",
       " 'cass.': <gensim.models.keyedvectors.Vocab at 0x25e6312cc48>,\n",
       " 'some': <gensim.models.keyedvectors.Vocab at 0x25e6312cc88>,\n",
       " 'part': <gensim.models.keyedvectors.Vocab at 0x25e6312ccc8>,\n",
       " 'spirit': <gensim.models.keyedvectors.Vocab at 0x25e6312cd08>,\n",
       " 'antony:': <gensim.models.keyedvectors.Vocab at 0x25e6312cd48>,\n",
       " 'cassius': <gensim.models.keyedvectors.Vocab at 0x25e6312cd88>,\n",
       " 'eyes,': <gensim.models.keyedvectors.Vocab at 0x25e6312cdc8>,\n",
       " 'shew': <gensim.models.keyedvectors.Vocab at 0x25e6312ce08>,\n",
       " 'loue,': <gensim.models.keyedvectors.Vocab at 0x25e6312ce48>,\n",
       " 'was': <gensim.models.keyedvectors.Vocab at 0x25e6312ce88>,\n",
       " 'beare': <gensim.models.keyedvectors.Vocab at 0x25e6312cec8>,\n",
       " 'too': <gensim.models.keyedvectors.Vocab at 0x25e6312cf08>,\n",
       " 'strange': <gensim.models.keyedvectors.Vocab at 0x25e6312cf48>,\n",
       " 'hand': <gensim.models.keyedvectors.Vocab at 0x25e6312cf88>,\n",
       " 'friend,': <gensim.models.keyedvectors.Vocab at 0x25e6312cfc8>,\n",
       " 'loues': <gensim.models.keyedvectors.Vocab at 0x25e6312f048>,\n",
       " 'bru.': <gensim.models.keyedvectors.Vocab at 0x25e6312f088>,\n",
       " 'looke,': <gensim.models.keyedvectors.Vocab at 0x25e6312f0c8>,\n",
       " 'turne': <gensim.models.keyedvectors.Vocab at 0x25e6312f108>,\n",
       " 'onely': <gensim.models.keyedvectors.Vocab at 0x25e6312f148>,\n",
       " 'selfe,': <gensim.models.keyedvectors.Vocab at 0x25e6312f188>,\n",
       " 'giue': <gensim.models.keyedvectors.Vocab at 0x25e6312f1c8>,\n",
       " 'therefore': <gensim.models.keyedvectors.Vocab at 0x25e6312f208>,\n",
       " 'friends': <gensim.models.keyedvectors.Vocab at 0x25e6312f248>,\n",
       " 'any': <gensim.models.keyedvectors.Vocab at 0x25e6312f288>,\n",
       " 'further': <gensim.models.keyedvectors.Vocab at 0x25e6312f2c8>,\n",
       " 'brutus': <gensim.models.keyedvectors.Vocab at 0x25e6312f308>,\n",
       " 'himselfe': <gensim.models.keyedvectors.Vocab at 0x25e6312f348>,\n",
       " 'at': <gensim.models.keyedvectors.Vocab at 0x25e6312f388>,\n",
       " 'loue': <gensim.models.keyedvectors.Vocab at 0x25e6312f3c8>,\n",
       " 'other': <gensim.models.keyedvectors.Vocab at 0x25e6312f408>,\n",
       " 'much': <gensim.models.keyedvectors.Vocab at 0x25e6312f448>,\n",
       " 'meanes': <gensim.models.keyedvectors.Vocab at 0x25e6312f488>,\n",
       " 'mine': <gensim.models.keyedvectors.Vocab at 0x25e6312f4c8>,\n",
       " 'hath': <gensim.models.keyedvectors.Vocab at 0x25e6312f508>,\n",
       " 'worthy': <gensim.models.keyedvectors.Vocab at 0x25e6312f548>,\n",
       " 'tell': <gensim.models.keyedvectors.Vocab at 0x25e6312f588>,\n",
       " 'brutus.': <gensim.models.keyedvectors.Vocab at 0x25e6312f5c8>,\n",
       " 'cassius:': <gensim.models.keyedvectors.Vocab at 0x25e6312f608>,\n",
       " 'things': <gensim.models.keyedvectors.Vocab at 0x25e6312f648>,\n",
       " 'cassius.': <gensim.models.keyedvectors.Vocab at 0x25e6312f688>,\n",
       " \"'tis\": <gensim.models.keyedvectors.Vocab at 0x25e6312f6c8>,\n",
       " 'very': <gensim.models.keyedvectors.Vocab at 0x25e6312f708>,\n",
       " 'such': <gensim.models.keyedvectors.Vocab at 0x25e6312f748>,\n",
       " 'might': <gensim.models.keyedvectors.Vocab at 0x25e6312f788>,\n",
       " 'noble': <gensim.models.keyedvectors.Vocab at 0x25e6312f7c8>,\n",
       " 'had': <gensim.models.keyedvectors.Vocab at 0x25e6312f808>,\n",
       " 'eyes': <gensim.models.keyedvectors.Vocab at 0x25e6312f848>,\n",
       " 'seeke': <gensim.models.keyedvectors.Vocab at 0x25e6312f888>,\n",
       " 'cas.': <gensim.models.keyedvectors.Vocab at 0x25e6312f8c8>,\n",
       " 'since': <gensim.models.keyedvectors.Vocab at 0x25e6312f908>,\n",
       " 'know,': <gensim.models.keyedvectors.Vocab at 0x25e6312f948>,\n",
       " 'cannot': <gensim.models.keyedvectors.Vocab at 0x25e6312f988>,\n",
       " 'well': <gensim.models.keyedvectors.Vocab at 0x25e6312f9c8>,\n",
       " 'gentle': <gensim.models.keyedvectors.Vocab at 0x25e6312fa08>,\n",
       " 'were': <gensim.models.keyedvectors.Vocab at 0x25e6312fa48>,\n",
       " 'common': <gensim.models.keyedvectors.Vocab at 0x25e6312fa88>,\n",
       " 'or': <gensim.models.keyedvectors.Vocab at 0x25e6312fac8>,\n",
       " 'did': <gensim.models.keyedvectors.Vocab at 0x25e6312fb08>,\n",
       " 'vse': <gensim.models.keyedvectors.Vocab at 0x25e6312fb48>,\n",
       " 'hold': <gensim.models.keyedvectors.Vocab at 0x25e6312fb88>,\n",
       " 'feare,': <gensim.models.keyedvectors.Vocab at 0x25e6312fbc8>,\n",
       " 'people': <gensim.models.keyedvectors.Vocab at 0x25e6312fc08>,\n",
       " 'i,': <gensim.models.keyedvectors.Vocab at 0x25e6312fc48>,\n",
       " 'feare': <gensim.models.keyedvectors.Vocab at 0x25e6312fc88>,\n",
       " 'thinke': <gensim.models.keyedvectors.Vocab at 0x25e6312fcc8>,\n",
       " 'it,': <gensim.models.keyedvectors.Vocab at 0x25e6312fd08>,\n",
       " 'generall': <gensim.models.keyedvectors.Vocab at 0x25e6312fd48>,\n",
       " 'honor': <gensim.models.keyedvectors.Vocab at 0x25e6312fd88>,\n",
       " 'one': <gensim.models.keyedvectors.Vocab at 0x25e6312fdc8>,\n",
       " 'death': <gensim.models.keyedvectors.Vocab at 0x25e6312fe08>,\n",
       " 'looke': <gensim.models.keyedvectors.Vocab at 0x25e6312fe48>,\n",
       " 'both': <gensim.models.keyedvectors.Vocab at 0x25e6312fe88>,\n",
       " 'name': <gensim.models.keyedvectors.Vocab at 0x25e6312fec8>,\n",
       " 'well,': <gensim.models.keyedvectors.Vocab at 0x25e6312ff08>,\n",
       " 'be,': <gensim.models.keyedvectors.Vocab at 0x25e6312ff48>,\n",
       " 'you,': <gensim.models.keyedvectors.Vocab at 0x25e6312ff88>,\n",
       " 'once,': <gensim.models.keyedvectors.Vocab at 0x25e6312ffc8>,\n",
       " 'angry': <gensim.models.keyedvectors.Vocab at 0x25e63133048>,\n",
       " 'word,': <gensim.models.keyedvectors.Vocab at 0x25e63133088>,\n",
       " 'hearts': <gensim.models.keyedvectors.Vocab at 0x25e631330c8>,\n",
       " 'ere': <gensim.models.keyedvectors.Vocab at 0x25e63133108>,\n",
       " 'could': <gensim.models.keyedvectors.Vocab at 0x25e63133148>,\n",
       " 'so,': <gensim.models.keyedvectors.Vocab at 0x25e63133188>,\n",
       " 'man,': <gensim.models.keyedvectors.Vocab at 0x25e631331c8>,\n",
       " 'him.': <gensim.models.keyedvectors.Vocab at 0x25e63133208>,\n",
       " 'fit': <gensim.models.keyedvectors.Vocab at 0x25e63133248>,\n",
       " 'him,': <gensim.models.keyedvectors.Vocab at 0x25e63133288>,\n",
       " 'marke': <gensim.models.keyedvectors.Vocab at 0x25e631332c8>,\n",
       " 'how': <gensim.models.keyedvectors.Vocab at 0x25e63133308>,\n",
       " 'true,': <gensim.models.keyedvectors.Vocab at 0x25e63133348>,\n",
       " 'same': <gensim.models.keyedvectors.Vocab at 0x25e63133388>,\n",
       " 'whose': <gensim.models.keyedvectors.Vocab at 0x25e631333c8>,\n",
       " 'world,': <gensim.models.keyedvectors.Vocab at 0x25e63133408>,\n",
       " 'romans': <gensim.models.keyedvectors.Vocab at 0x25e63133448>,\n",
       " 'titinius,': <gensim.models.keyedvectors.Vocab at 0x25e63133488>,\n",
       " 'sicke': <gensim.models.keyedvectors.Vocab at 0x25e631334c8>,\n",
       " 'ye': <gensim.models.keyedvectors.Vocab at 0x25e63133508>,\n",
       " 'gods,': <gensim.models.keyedvectors.Vocab at 0x25e63133548>,\n",
       " 'should': <gensim.models.keyedvectors.Vocab at 0x25e63133588>,\n",
       " 'world': <gensim.models.keyedvectors.Vocab at 0x25e631335c8>,\n",
       " 'like': <gensim.models.keyedvectors.Vocab at 0x25e63133608>,\n",
       " 'vnder': <gensim.models.keyedvectors.Vocab at 0x25e63133648>,\n",
       " 'selues': <gensim.models.keyedvectors.Vocab at 0x25e63133688>,\n",
       " 'yours': <gensim.models.keyedvectors.Vocab at 0x25e631336c8>,\n",
       " 'them,': <gensim.models.keyedvectors.Vocab at 0x25e63133708>,\n",
       " 'caesar.': <gensim.models.keyedvectors.Vocab at 0x25e63133748>,\n",
       " 'hast': <gensim.models.keyedvectors.Vocab at 0x25e63133788>,\n",
       " 'went': <gensim.models.keyedvectors.Vocab at 0x25e631337c8>,\n",
       " 'say': <gensim.models.keyedvectors.Vocab at 0x25e63133808>,\n",
       " 'rome': <gensim.models.keyedvectors.Vocab at 0x25e63133848>,\n",
       " 'indeed,': <gensim.models.keyedvectors.Vocab at 0x25e63133888>,\n",
       " 'man.': <gensim.models.keyedvectors.Vocab at 0x25e631338c8>,\n",
       " 'heard': <gensim.models.keyedvectors.Vocab at 0x25e63133908>,\n",
       " 'nothing': <gensim.models.keyedvectors.Vocab at 0x25e63133948>,\n",
       " 'this,': <gensim.models.keyedvectors.Vocab at 0x25e63133988>,\n",
       " 'times': <gensim.models.keyedvectors.Vocab at 0x25e631339c8>,\n",
       " 'meete': <gensim.models.keyedvectors.Vocab at 0x25e63133a08>,\n",
       " 'high': <gensim.models.keyedvectors.Vocab at 0x25e63133a48>,\n",
       " 'then,': <gensim.models.keyedvectors.Vocab at 0x25e63133a88>,\n",
       " 'this:': <gensim.models.keyedvectors.Vocab at 0x25e63133ac8>,\n",
       " 'rather': <gensim.models.keyedvectors.Vocab at 0x25e63133b08>,\n",
       " 'sonne': <gensim.models.keyedvectors.Vocab at 0x25e63133b48>,\n",
       " 'weake': <gensim.models.keyedvectors.Vocab at 0x25e63133b88>,\n",
       " 'words': <gensim.models.keyedvectors.Vocab at 0x25e63133bc8>,\n",
       " 'thus': <gensim.models.keyedvectors.Vocab at 0x25e63133c08>,\n",
       " 'fire': <gensim.models.keyedvectors.Vocab at 0x25e63133c48>,\n",
       " 'done,': <gensim.models.keyedvectors.Vocab at 0x25e63133c88>,\n",
       " 'caska': <gensim.models.keyedvectors.Vocab at 0x25e63133cc8>,\n",
       " 'note': <gensim.models.keyedvectors.Vocab at 0x25e63133d08>,\n",
       " 'day': <gensim.models.keyedvectors.Vocab at 0x25e63133d48>,\n",
       " 'so:': <gensim.models.keyedvectors.Vocab at 0x25e63133d88>,\n",
       " 'cicero': <gensim.models.keyedvectors.Vocab at 0x25e63133dc8>,\n",
       " 'lookes': <gensim.models.keyedvectors.Vocab at 0x25e63133e08>,\n",
       " 'seene': <gensim.models.keyedvectors.Vocab at 0x25e63133e48>,\n",
       " 'capitoll': <gensim.models.keyedvectors.Vocab at 0x25e63133e88>,\n",
       " 'being': <gensim.models.keyedvectors.Vocab at 0x25e63133ec8>,\n",
       " 'caes': <gensim.models.keyedvectors.Vocab at 0x25e63133f08>,\n",
       " 'sleepe': <gensim.models.keyedvectors.Vocab at 0x25e63133f48>,\n",
       " 'dangerous': <gensim.models.keyedvectors.Vocab at 0x25e63133f88>,\n",
       " 'not:': <gensim.models.keyedvectors.Vocab at 0x25e63133fc8>,\n",
       " 'through': <gensim.models.keyedvectors.Vocab at 0x25e63136048>,\n",
       " 'himselfe,': <gensim.models.keyedvectors.Vocab at 0x25e63136088>,\n",
       " 'neuer': <gensim.models.keyedvectors.Vocab at 0x25e631360c8>,\n",
       " 'thee': <gensim.models.keyedvectors.Vocab at 0x25e63136108>,\n",
       " 'right': <gensim.models.keyedvectors.Vocab at 0x25e63136148>,\n",
       " 'hand,': <gensim.models.keyedvectors.Vocab at 0x25e63136188>,\n",
       " 'speake': <gensim.models.keyedvectors.Vocab at 0x25e631361c8>,\n",
       " 'not?': <gensim.models.keyedvectors.Vocab at 0x25e63136208>,\n",
       " 'crowne': <gensim.models.keyedvectors.Vocab at 0x25e63136248>,\n",
       " \"offer'd\": <gensim.models.keyedvectors.Vocab at 0x25e63136288>,\n",
       " 'him;': <gensim.models.keyedvectors.Vocab at 0x25e631362c8>,\n",
       " 'backe': <gensim.models.keyedvectors.Vocab at 0x25e63136308>,\n",
       " 'fell': <gensim.models.keyedvectors.Vocab at 0x25e63136348>,\n",
       " 'last': <gensim.models.keyedvectors.Vocab at 0x25e63136388>,\n",
       " 'cry': <gensim.models.keyedvectors.Vocab at 0x25e631363c8>,\n",
       " 'hee': <gensim.models.keyedvectors.Vocab at 0x25e63136408>,\n",
       " 'it:': <gensim.models.keyedvectors.Vocab at 0x25e63136448>,\n",
       " 'it.': <gensim.models.keyedvectors.Vocab at 0x25e63136488>,\n",
       " 'that,': <gensim.models.keyedvectors.Vocab at 0x25e631364c8>,\n",
       " 'still': <gensim.models.keyedvectors.Vocab at 0x25e63136508>,\n",
       " 'hands,': <gensim.models.keyedvectors.Vocab at 0x25e63136548>,\n",
       " 'owne': <gensim.models.keyedvectors.Vocab at 0x25e63136588>,\n",
       " 'part,': <gensim.models.keyedvectors.Vocab at 0x25e631365c8>,\n",
       " 'durst': <gensim.models.keyedvectors.Vocab at 0x25e63136608>,\n",
       " 'you:': <gensim.models.keyedvectors.Vocab at 0x25e63136648>,\n",
       " 'no,': <gensim.models.keyedvectors.Vocab at 0x25e63136688>,\n",
       " 'meane': <gensim.models.keyedvectors.Vocab at 0x25e631366c8>,\n",
       " 'sure': <gensim.models.keyedvectors.Vocab at 0x25e63136708>,\n",
       " 'doe': <gensim.models.keyedvectors.Vocab at 0x25e63136748>,\n",
       " 'true': <gensim.models.keyedvectors.Vocab at 0x25e63136788>,\n",
       " 'came': <gensim.models.keyedvectors.Vocab at 0x25e631367c8>,\n",
       " 'vnto': <gensim.models.keyedvectors.Vocab at 0x25e63136808>,\n",
       " 'downe,': <gensim.models.keyedvectors.Vocab at 0x25e63136848>,\n",
       " 'beene': <gensim.models.keyedvectors.Vocab at 0x25e63136888>,\n",
       " 'thing': <gensim.models.keyedvectors.Vocab at 0x25e631368c8>,\n",
       " 'three': <gensim.models.keyedvectors.Vocab at 0x25e63136908>,\n",
       " \"there's\": <gensim.models.keyedvectors.Vocab at 0x25e63136948>,\n",
       " 'done': <gensim.models.keyedvectors.Vocab at 0x25e63136988>,\n",
       " 'those': <gensim.models.keyedvectors.Vocab at 0x25e631369c8>,\n",
       " 'me.': <gensim.models.keyedvectors.Vocab at 0x25e63136a08>,\n",
       " 'fare': <gensim.models.keyedvectors.Vocab at 0x25e63136a48>,\n",
       " 'well.': <gensim.models.keyedvectors.Vocab at 0x25e63136a88>,\n",
       " 'yet,': <gensim.models.keyedvectors.Vocab at 0x25e63136ac8>,\n",
       " 'remember': <gensim.models.keyedvectors.Vocab at 0x25e63136b08>,\n",
       " 'night,': <gensim.models.keyedvectors.Vocab at 0x25e63136b48>,\n",
       " 'forth': <gensim.models.keyedvectors.Vocab at 0x25e63136b88>,\n",
       " 'farewell': <gensim.models.keyedvectors.Vocab at 0x25e63136bc8>,\n",
       " 'enter.': <gensim.models.keyedvectors.Vocab at 0x25e63136c08>,\n",
       " 'now,': <gensim.models.keyedvectors.Vocab at 0x25e63136c48>,\n",
       " 'better': <gensim.models.keyedvectors.Vocab at 0x25e63136c88>,\n",
       " 'please': <gensim.models.keyedvectors.Vocab at 0x25e63136cc8>,\n",
       " 'will,': <gensim.models.keyedvectors.Vocab at 0x25e63136d08>,\n",
       " 'exit': <gensim.models.keyedvectors.Vocab at 0x25e63136d48>,\n",
       " 'see,': <gensim.models.keyedvectors.Vocab at 0x25e63136d88>,\n",
       " 'seuerall': <gensim.models.keyedvectors.Vocab at 0x25e63136dc8>,\n",
       " 'dayes': <gensim.models.keyedvectors.Vocab at 0x25e63136e08>,\n",
       " 'brought': <gensim.models.keyedvectors.Vocab at 0x25e63136e48>,\n",
       " 'send': <gensim.models.keyedvectors.Vocab at 0x25e63136e88>,\n",
       " 'left': <gensim.models.keyedvectors.Vocab at 0x25e63136ec8>,\n",
       " 'fire,': <gensim.models.keyedvectors.Vocab at 0x25e63136f08>,\n",
       " 'sword,': <gensim.models.keyedvectors.Vocab at 0x25e63136f48>,\n",
       " 'against': <gensim.models.keyedvectors.Vocab at 0x25e63136f88>,\n",
       " 'night': <gensim.models.keyedvectors.Vocab at 0x25e63136fc8>,\n",
       " 'euen': <gensim.models.keyedvectors.Vocab at 0x25e63139048>,\n",
       " 'word': <gensim.models.keyedvectors.Vocab at 0x25e63139088>,\n",
       " 'morrow': <gensim.models.keyedvectors.Vocab at 0x25e631390c8>,\n",
       " 'voyce': <gensim.models.keyedvectors.Vocab at 0x25e63139108>,\n",
       " 'this?': <gensim.models.keyedvectors.Vocab at 0x25e63139148>,\n",
       " 'full': <gensim.models.keyedvectors.Vocab at 0x25e63139188>,\n",
       " 'life,': <gensim.models.keyedvectors.Vocab at 0x25e631391c8>,\n",
       " 'cause,': <gensim.models.keyedvectors.Vocab at 0x25e63139208>,\n",
       " 'change': <gensim.models.keyedvectors.Vocab at 0x25e63139248>,\n",
       " 'spirits,': <gensim.models.keyedvectors.Vocab at 0x25e63139288>,\n",
       " 'not,': <gensim.models.keyedvectors.Vocab at 0x25e631392c8>,\n",
       " 'dead,': <gensim.models.keyedvectors.Vocab at 0x25e63139308>,\n",
       " 'here': <gensim.models.keyedvectors.Vocab at 0x25e63139348>,\n",
       " 'strong': <gensim.models.keyedvectors.Vocab at 0x25e63139388>,\n",
       " 'life': <gensim.models.keyedvectors.Vocab at 0x25e631393c8>,\n",
       " 'beares': <gensim.models.keyedvectors.Vocab at 0x25e63139408>,\n",
       " 'base': <gensim.models.keyedvectors.Vocab at 0x25e63139448>,\n",
       " 'vile': <gensim.models.keyedvectors.Vocab at 0x25e63139488>,\n",
       " 'stay': <gensim.models.keyedvectors.Vocab at 0x25e631394c8>,\n",
       " 'cinna.': <gensim.models.keyedvectors.Vocab at 0x25e63139508>,\n",
       " 'cinna,': <gensim.models.keyedvectors.Vocab at 0x25e63139548>,\n",
       " 'metellus': <gensim.models.keyedvectors.Vocab at 0x25e63139588>,\n",
       " 'two': <gensim.models.keyedvectors.Vocab at 0x25e631395c8>,\n",
       " 'take': <gensim.models.keyedvectors.Vocab at 0x25e63139608>,\n",
       " 'vs.': <gensim.models.keyedvectors.Vocab at 0x25e63139648>,\n",
       " 'decius': <gensim.models.keyedvectors.Vocab at 0x25e63139688>,\n",
       " 'trebonius': <gensim.models.keyedvectors.Vocab at 0x25e631396c8>,\n",
       " 'appeare': <gensim.models.keyedvectors.Vocab at 0x25e63139708>,\n",
       " 'vs,': <gensim.models.keyedvectors.Vocab at 0x25e63139748>,\n",
       " 'awake': <gensim.models.keyedvectors.Vocab at 0x25e63139788>,\n",
       " 'lucius,': <gensim.models.keyedvectors.Vocab at 0x25e631397c8>,\n",
       " 'lucius.': <gensim.models.keyedvectors.Vocab at 0x25e63139808>,\n",
       " 'luc.': <gensim.models.keyedvectors.Vocab at 0x25e63139848>,\n",
       " 'lord?': <gensim.models.keyedvectors.Vocab at 0x25e63139888>,\n",
       " 'call': <gensim.models.keyedvectors.Vocab at 0x25e631398c8>,\n",
       " 'is,': <gensim.models.keyedvectors.Vocab at 0x25e63139908>,\n",
       " 'least': <gensim.models.keyedvectors.Vocab at 0x25e63139948>,\n",
       " 'kill': <gensim.models.keyedvectors.Vocab at 0x25e63139988>,\n",
       " 'found': <gensim.models.keyedvectors.Vocab at 0x25e631399c8>,\n",
       " 'lye': <gensim.models.keyedvectors.Vocab at 0x25e63139a08>,\n",
       " 'day:': <gensim.models.keyedvectors.Vocab at 0x25e63139a48>,\n",
       " 'first': <gensim.models.keyedvectors.Vocab at 0x25e63139a88>,\n",
       " 'bring': <gensim.models.keyedvectors.Vocab at 0x25e63139ac8>,\n",
       " 'reade': <gensim.models.keyedvectors.Vocab at 0x25e63139b08>,\n",
       " 'tooke': <gensim.models.keyedvectors.Vocab at 0x25e63139b48>,\n",
       " 'body': <gensim.models.keyedvectors.Vocab at 0x25e63139b88>,\n",
       " 'little': <gensim.models.keyedvectors.Vocab at 0x25e63139bc8>,\n",
       " 'brother': <gensim.models.keyedvectors.Vocab at 0x25e63139c08>,\n",
       " 'wilt': <gensim.models.keyedvectors.Vocab at 0x25e63139c48>,\n",
       " 'none': <gensim.models.keyedvectors.Vocab at 0x25e63139c88>,\n",
       " 'hide': <gensim.models.keyedvectors.Vocab at 0x25e63139cc8>,\n",
       " 'night:': <gensim.models.keyedvectors.Vocab at 0x25e63139d08>,\n",
       " 'roman': <gensim.models.keyedvectors.Vocab at 0x25e63139d48>,\n",
       " 'you.': <gensim.models.keyedvectors.Vocab at 0x25e63139d88>,\n",
       " 'welcome': <gensim.models.keyedvectors.Vocab at 0x25e63139dc8>,\n",
       " 'cymber': <gensim.models.keyedvectors.Vocab at 0x25e63139e08>,\n",
       " 'decius.': <gensim.models.keyedvectors.Vocab at 0x25e63139e48>,\n",
       " 'breake': <gensim.models.keyedvectors.Vocab at 0x25e63139e88>,\n",
       " 'heere?': <gensim.models.keyedvectors.Vocab at 0x25e63139ec8>,\n",
       " 'cin.': <gensim.models.keyedvectors.Vocab at 0x25e63139f08>,\n",
       " 'heere,': <gensim.models.keyedvectors.Vocab at 0x25e63139f48>,\n",
       " 'hands': <gensim.models.keyedvectors.Vocab at 0x25e63139f88>,\n",
       " 'cause': <gensim.models.keyedvectors.Vocab at 0x25e63139fc8>,\n",
       " 'romans,': <gensim.models.keyedvectors.Vocab at 0x25e6313c048>,\n",
       " 'blood': <gensim.models.keyedvectors.Vocab at 0x25e6313c088>,\n",
       " 'him?': <gensim.models.keyedvectors.Vocab at 0x25e6313c0c8>,\n",
       " 'antony,': <gensim.models.keyedvectors.Vocab at 0x25e6313c108>,\n",
       " 'farre': <gensim.models.keyedvectors.Vocab at 0x25e6313c148>,\n",
       " 'seeme': <gensim.models.keyedvectors.Vocab at 0x25e6313c188>,\n",
       " 'caius': <gensim.models.keyedvectors.Vocab at 0x25e6313c1c8>,\n",
       " 'cut': <gensim.models.keyedvectors.Vocab at 0x25e6313c208>,\n",
       " 'death,': <gensim.models.keyedvectors.Vocab at 0x25e6313c248>,\n",
       " \"let's\": <gensim.models.keyedvectors.Vocab at 0x25e6313c288>,\n",
       " 'friends,': <gensim.models.keyedvectors.Vocab at 0x25e6313c2c8>,\n",
       " 'stirre': <gensim.models.keyedvectors.Vocab at 0x25e6313c308>,\n",
       " 'dye': <gensim.models.keyedvectors.Vocab at 0x25e6313c348>,\n",
       " 'liue,': <gensim.models.keyedvectors.Vocab at 0x25e6313c388>,\n",
       " 'peace,': <gensim.models.keyedvectors.Vocab at 0x25e6313c3c8>,\n",
       " 'whether': <gensim.models.keyedvectors.Vocab at 0x25e6313c408>,\n",
       " 'fetch': <gensim.models.keyedvectors.Vocab at 0x25e6313c448>,\n",
       " \"wee'l\": <gensim.models.keyedvectors.Vocab at 0x25e6313c488>,\n",
       " 'por.': <gensim.models.keyedvectors.Vocab at 0x25e6313c4c8>,\n",
       " 'gaue': <gensim.models.keyedvectors.Vocab at 0x25e6313c508>,\n",
       " 'lord,': <gensim.models.keyedvectors.Vocab at 0x25e6313c548>,\n",
       " 'portia': <gensim.models.keyedvectors.Vocab at 0x25e6313c588>,\n",
       " 'within': <gensim.models.keyedvectors.Vocab at 0x25e6313c5c8>,\n",
       " 'place': <gensim.models.keyedvectors.Vocab at 0x25e6313c608>,\n",
       " 'talke': <gensim.models.keyedvectors.Vocab at 0x25e6313c648>,\n",
       " 'honourable': <gensim.models.keyedvectors.Vocab at 0x25e6313c688>,\n",
       " 'deere': <gensim.models.keyedvectors.Vocab at 0x25e6313c6c8>,\n",
       " 'heart': <gensim.models.keyedvectors.Vocab at 0x25e6313c708>,\n",
       " 'thee,': <gensim.models.keyedvectors.Vocab at 0x25e6313c748>,\n",
       " 'lucius': <gensim.models.keyedvectors.Vocab at 0x25e6313c788>,\n",
       " 'ligarius,': <gensim.models.keyedvectors.Vocab at 0x25e6313c7c8>,\n",
       " 'boy,': <gensim.models.keyedvectors.Vocab at 0x25e6313c808>,\n",
       " 'cai.': <gensim.models.keyedvectors.Vocab at 0x25e6313c848>,\n",
       " 'braue': <gensim.models.keyedvectors.Vocab at 0x25e6313c888>,\n",
       " 'seruant.': <gensim.models.keyedvectors.Vocab at 0x25e6313c8c8>,\n",
       " 'ser.': <gensim.models.keyedvectors.Vocab at 0x25e6313c908>,\n",
       " 'house': <gensim.models.keyedvectors.Vocab at 0x25e6313c948>,\n",
       " 'end': <gensim.models.keyedvectors.Vocab at 0x25e6313c988>,\n",
       " 'mighty': <gensim.models.keyedvectors.Vocab at 0x25e6313c9c8>,\n",
       " 'come,': <gensim.models.keyedvectors.Vocab at 0x25e6313ca08>,\n",
       " 'house,': <gensim.models.keyedvectors.Vocab at 0x25e6313ca48>,\n",
       " 'mark': <gensim.models.keyedvectors.Vocab at 0x25e6313ca88>,\n",
       " 'deci.': <gensim.models.keyedvectors.Vocab at 0x25e6313cac8>,\n",
       " 'she': <gensim.models.keyedvectors.Vocab at 0x25e6313cb08>,\n",
       " 'pardon': <gensim.models.keyedvectors.Vocab at 0x25e6313cb48>,\n",
       " 'publius': <gensim.models.keyedvectors.Vocab at 0x25e6313cb88>,\n",
       " 'prepare': <gensim.models.keyedvectors.Vocab at 0x25e6313cbc8>,\n",
       " 'blame': <gensim.models.keyedvectors.Vocab at 0x25e6313cc08>,\n",
       " 'will:': <gensim.models.keyedvectors.Vocab at 0x25e6313cc48>,\n",
       " 'thee.': <gensim.models.keyedvectors.Vocab at 0x25e6313cc88>,\n",
       " 'traitors': <gensim.models.keyedvectors.Vocab at 0x25e6313ccc8>,\n",
       " 'suite': <gensim.models.keyedvectors.Vocab at 0x25e6313cd08>,\n",
       " 'read': <gensim.models.keyedvectors.Vocab at 0x25e6313cd48>,\n",
       " 'friend': <gensim.models.keyedvectors.Vocab at 0x25e6313cd88>,\n",
       " 'master': <gensim.models.keyedvectors.Vocab at 0x25e6313cdc8>,\n",
       " \"lou'd\": <gensim.models.keyedvectors.Vocab at 0x25e6313ce08>,\n",
       " 'dead': <gensim.models.keyedvectors.Vocab at 0x25e6313ce48>,\n",
       " 'though': <gensim.models.keyedvectors.Vocab at 0x25e6313ce88>,\n",
       " 'bloody': <gensim.models.keyedvectors.Vocab at 0x25e6313cec8>,\n",
       " 'wrong': <gensim.models.keyedvectors.Vocab at 0x25e6313cf08>,\n",
       " 'marcus': <gensim.models.keyedvectors.Vocab at 0x25e6313cf48>,\n",
       " \"did'st\": <gensim.models.keyedvectors.Vocab at 0x25e6313cf88>,\n",
       " 'so.': <gensim.models.keyedvectors.Vocab at 0x25e6313cfc8>,\n",
       " 'octauius': <gensim.models.keyedvectors.Vocab at 0x25e63141048>,\n",
       " 'yong': <gensim.models.keyedvectors.Vocab at 0x25e63141088>,\n",
       " 'octauius,': <gensim.models.keyedvectors.Vocab at 0x25e631410c8>,\n",
       " '2.': <gensim.models.keyedvectors.Vocab at 0x25e63141108>,\n",
       " '3.': <gensim.models.keyedvectors.Vocab at 0x25e63141148>,\n",
       " '1.': <gensim.models.keyedvectors.Vocab at 0x25e63141188>,\n",
       " '4.': <gensim.models.keyedvectors.Vocab at 0x25e631411c8>,\n",
       " '1': <gensim.models.keyedvectors.Vocab at 0x25e63141208>,\n",
       " '3': <gensim.models.keyedvectors.Vocab at 0x25e63141248>,\n",
       " '4': <gensim.models.keyedvectors.Vocab at 0x25e63141288>,\n",
       " '2': <gensim.models.keyedvectors.Vocab at 0x25e631412c8>,\n",
       " 'heart,': <gensim.models.keyedvectors.Vocab at 0x25e63141308>,\n",
       " 'away,': <gensim.models.keyedvectors.Vocab at 0x25e63141348>,\n",
       " 'cinna': <gensim.models.keyedvectors.Vocab at 0x25e63141388>,\n",
       " 'octa.': <gensim.models.keyedvectors.Vocab at 0x25e631413c8>,\n",
       " 'meet': <gensim.models.keyedvectors.Vocab at 0x25e63141408>,\n",
       " 'lucillius,': <gensim.models.keyedvectors.Vocab at 0x25e63141448>,\n",
       " 'titinius': <gensim.models.keyedvectors.Vocab at 0x25e63141488>,\n",
       " 'pindarus': <gensim.models.keyedvectors.Vocab at 0x25e631414c8>,\n",
       " 'lucil.': <gensim.models.keyedvectors.Vocab at 0x25e63141508>,\n",
       " 'ill': <gensim.models.keyedvectors.Vocab at 0x25e63141548>,\n",
       " 'lucillius': <gensim.models.keyedvectors.Vocab at 0x25e63141588>,\n",
       " 'tent': <gensim.models.keyedvectors.Vocab at 0x25e631415c8>,\n",
       " 'messala': <gensim.models.keyedvectors.Vocab at 0x25e63141608>,\n",
       " 'messala,': <gensim.models.keyedvectors.Vocab at 0x25e63141648>,\n",
       " 'philippi': <gensim.models.keyedvectors.Vocab at 0x25e63141688>,\n",
       " 'messa.': <gensim.models.keyedvectors.Vocab at 0x25e631416c8>,\n",
       " 'enemy': <gensim.models.keyedvectors.Vocab at 0x25e63141708>,\n",
       " 'tit.': <gensim.models.keyedvectors.Vocab at 0x25e63141748>,\n",
       " 'sword': <gensim.models.keyedvectors.Vocab at 0x25e63141788>,\n",
       " 'cato,': <gensim.models.keyedvectors.Vocab at 0x25e631417c8>,\n",
       " 'alarum.': <gensim.models.keyedvectors.Vocab at 0x25e63141808>,\n",
       " 'titin.': <gensim.models.keyedvectors.Vocab at 0x25e63141848>,\n",
       " 'strato,': <gensim.models.keyedvectors.Vocab at 0x25e63141888>,\n",
       " 'clit.': <gensim.models.keyedvectors.Vocab at 0x25e631418c8>}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import gensim.models as gmodels\n",
    "\n",
    "\n",
    "# get sentece from the raw txt\n",
    "f = open('data_home_assignment_2\\shakespeare-caesar.txt')\n",
    "raw = f.read()\n",
    "sent_tokens = nltk.sent_tokenize(raw)\n",
    "\n",
    "#preprocessing the sentence: strip unnecesary data normalizing cases\n",
    "sentences=[]\n",
    "for sent in sent_tokens:\n",
    "    s = re.split(r'\\s+',sent.strip()) #using re to remove \\n\\n \\t and so on\n",
    "    sentence = [w.lower() for w in s] #normalizing cases\n",
    "    # print(string.punctuation)\n",
    "    sentences.append(sentence)\n",
    "    \n",
    "model = gmodels.Word2Vec(sentences=sentences)\n",
    "model.wv.vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word similarity with pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of understanding how good the obtained embeddings are is the word similarity task. The file 'sim353.csv' contains a set of word pairs as well as their similarity as judged by humans (e.g., tiger,tiger,10). \n",
    "Also we provide a set of pre-trained embeddings in 'embeddings.pickle' in the form of a dictionary with words as keys and embeddings as values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Consider each word pair in the given file ('sim353.csv') and calculate the cosine similarity between them and then rank the word pairs based on the similarity value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red> how to deal with words that not in embedding?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Human (mean)</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>rank (cos.sim.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>money</td>\n",
       "      <td>cash</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.815317</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>money</td>\n",
       "      <td>cash</td>\n",
       "      <td>9.15</td>\n",
       "      <td>0.815317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>football</td>\n",
       "      <td>soccer</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.814274</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>championship</td>\n",
       "      <td>tournament</td>\n",
       "      <td>8.36</td>\n",
       "      <td>0.807413</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>man</td>\n",
       "      <td>woman</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.804799</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>football</td>\n",
       "      <td>basketball</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.799937</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>king</td>\n",
       "      <td>queen</td>\n",
       "      <td>8.58</td>\n",
       "      <td>0.759618</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>car</td>\n",
       "      <td>automobile</td>\n",
       "      <td>8.94</td>\n",
       "      <td>0.733075</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>physics</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0.729284</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>weather</td>\n",
       "      <td>forecast</td>\n",
       "      <td>8.34</td>\n",
       "      <td>0.716078</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>street</td>\n",
       "      <td>avenue</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0.708214</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>credit</td>\n",
       "      <td>card</td>\n",
       "      <td>8.06</td>\n",
       "      <td>0.689643</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>aluminum</td>\n",
       "      <td>metal</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.684565</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>type</td>\n",
       "      <td>kind</td>\n",
       "      <td>8.97</td>\n",
       "      <td>0.679077</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>coast</td>\n",
       "      <td>shore</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0.677802</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>sex</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>television</td>\n",
       "      <td>radio</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.674091</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>seafood</td>\n",
       "      <td>lobster</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.674077</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>computer</td>\n",
       "      <td>software</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.672374</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>day</td>\n",
       "      <td>summer</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.670856</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>fuck</td>\n",
       "      <td>sex</td>\n",
       "      <td>9.44</td>\n",
       "      <td>0.670561</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>calculation</td>\n",
       "      <td>computation</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0.669189</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>vodka</td>\n",
       "      <td>gin</td>\n",
       "      <td>8.46</td>\n",
       "      <td>0.668546</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bread</td>\n",
       "      <td>butter</td>\n",
       "      <td>6.19</td>\n",
       "      <td>0.667959</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>midday</td>\n",
       "      <td>noon</td>\n",
       "      <td>9.29</td>\n",
       "      <td>0.665748</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>drink</td>\n",
       "      <td>eat</td>\n",
       "      <td>6.87</td>\n",
       "      <td>0.664106</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>law</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.655002</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>psychology</td>\n",
       "      <td>psychiatry</td>\n",
       "      <td>8.08</td>\n",
       "      <td>0.650045</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>psychology</td>\n",
       "      <td>science</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.650004</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>shower</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>6.31</td>\n",
       "      <td>0.237645</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tiger</td>\n",
       "      <td>fauna</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0.226339</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>reason</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>lad</td>\n",
       "      <td>wizard</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.207744</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>sign</td>\n",
       "      <td>recess</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.206303</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>cup</td>\n",
       "      <td>tableware</td>\n",
       "      <td>6.85</td>\n",
       "      <td>0.206225</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>asylum</td>\n",
       "      <td>madhouse</td>\n",
       "      <td>8.87</td>\n",
       "      <td>0.199657</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>cup</td>\n",
       "      <td>object</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.197506</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>size</td>\n",
       "      <td>prominence</td>\n",
       "      <td>5.31</td>\n",
       "      <td>0.191225</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>cup</td>\n",
       "      <td>substance</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.190121</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>territory</td>\n",
       "      <td>kilometer</td>\n",
       "      <td>5.28</td>\n",
       "      <td>0.183836</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>production</td>\n",
       "      <td>hike</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.183246</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>king</td>\n",
       "      <td>cabbage</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.182654</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>chord</td>\n",
       "      <td>smile</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.181856</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>decoration</td>\n",
       "      <td>valor</td>\n",
       "      <td>5.63</td>\n",
       "      <td>0.181139</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>crane</td>\n",
       "      <td>implement</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.179740</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>impartiality</td>\n",
       "      <td>interest</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.172755</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>delay</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.171557</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>monk</td>\n",
       "      <td>slave</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.160540</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>precedent</td>\n",
       "      <td>collection</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.159243</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>glass</td>\n",
       "      <td>magician</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.158012</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>monk</td>\n",
       "      <td>oracle</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.138562</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>precedent</td>\n",
       "      <td>cognition</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.124228</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>precedent</td>\n",
       "      <td>group</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.122940</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>noon</td>\n",
       "      <td>string</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.122765</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>cup</td>\n",
       "      <td>entity</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.095603</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>professor</td>\n",
       "      <td>cucumber</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.088859</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>cup</td>\n",
       "      <td>artifact</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.045669</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>rooster</td>\n",
       "      <td>voyage</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.038883</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tiger</td>\n",
       "      <td>organism</td>\n",
       "      <td>4.77</td>\n",
       "      <td>0.036870</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 1        Word 2  Human (mean)   cos_sim  rank (cos.sim.)\n",
       "2           tiger         tiger         10.00  1.000000                1\n",
       "90          money          cash          9.08  0.815317                2\n",
       "30          money          cash          9.15  0.815317                3\n",
       "38       football        soccer          9.03  0.814274                4\n",
       "279  championship    tournament          8.36  0.807413                5\n",
       "289           man         woman          8.30  0.804799                6\n",
       "39       football    basketball          6.81  0.799937                7\n",
       "33           king         queen          8.58  0.759618                8\n",
       "59            car    automobile          8.94  0.733075                9\n",
       "48        physics     chemistry          7.35  0.729284               10\n",
       "331       weather      forecast          8.34  0.716078               11\n",
       "229        street        avenue          8.88  0.708214               12\n",
       "213        credit          card          8.06  0.689643               13\n",
       "319      aluminum         metal          7.83  0.684565               14\n",
       "220          type          kind          8.97  0.679077               15\n",
       "63          coast         shore          9.10  0.677802               16\n",
       "0            love           sex          6.77  0.677000               17\n",
       "9      television         radio          6.77  0.674091               18\n",
       "270       seafood       lobster          8.70  0.674077               19\n",
       "252      computer      software          8.50  0.672374               20\n",
       "282           day        summer          3.94  0.670856               21\n",
       "37           fuck           sex          9.44  0.670561               22\n",
       "241   calculation   computation          8.44  0.669189               23\n",
       "51          vodka           gin          8.46  0.668546               24\n",
       "12          bread        butter          6.19  0.667959               25\n",
       "66         midday          noon          9.29  0.665748               26\n",
       "56          drink           eat          6.87  0.664106               27\n",
       "42            law        lawyer          8.38  0.655002               28\n",
       "108    psychology    psychiatry          8.08  0.650045               29\n",
       "116    psychology       science          6.71  0.650004               30\n",
       "..            ...           ...           ...       ...              ...\n",
       "329        shower  thunderstorm          6.31  0.237645              306\n",
       "106         tiger         fauna          5.62  0.226339              307\n",
       "192        reason  hypertension          2.31  0.210041              308\n",
       "84            lad        wizard          0.92  0.207744              309\n",
       "156          sign        recess          2.38  0.206303              310\n",
       "134           cup     tableware          6.85  0.206225              311\n",
       "64         asylum      madhouse          8.87  0.199657              312\n",
       "137           cup        object          3.69  0.197506              313\n",
       "312          size    prominence          5.31  0.191225              314\n",
       "141           cup     substance          1.92  0.190121              315\n",
       "206     territory     kilometer          5.28  0.183836              316\n",
       "235    production          hike          1.75  0.183246              317\n",
       "32           king       cabbage          0.23  0.182654              318\n",
       "85          chord         smile          0.54  0.181856              319\n",
       "168    decoration         valor          5.63  0.181139              320\n",
       "73          crane     implement          2.69  0.179740              321\n",
       "226  impartiality      interest          5.16  0.172755              322\n",
       "171         delay        racism          1.19  0.171557              323\n",
       "82           monk         slave          0.92  0.160540              324\n",
       "130     precedent    collection          2.50  0.159243              325\n",
       "86          glass      magician          2.08  0.158012              326\n",
       "76           monk        oracle          5.00  0.138562              327\n",
       "128     precedent     cognition          2.81  0.124228              328\n",
       "131     precedent         group          1.77  0.122940              329\n",
       "87           noon        string          0.54  0.122765              330\n",
       "138           cup        entity          2.15  0.095603              331\n",
       "31      professor      cucumber          0.31  0.088859              332\n",
       "136           cup      artifact          2.92  0.045669              333\n",
       "88        rooster        voyage          0.62  0.038883              334\n",
       "105         tiger      organism          4.77  0.036870              335\n",
       "\n",
       "[335 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "#read from pick and csv\n",
    "pickle_in = open('data_home_assignment_2\\embeddings.pickle','rb')\n",
    "embeddings = pickle.load(pickle_in)\n",
    "csv_in = pd.read_csv('data_home_assignment_2\\sim353.csv',delimiter=',')\n",
    "df_sim353 = pd.DataFrame(csv_in)\n",
    "\n",
    "word1 = df_sim353['Word 1']\n",
    "word2 = df_sim353['Word 2']\n",
    "sim_human = df_sim353['Human (mean)']\n",
    "pairlen = len(word1)\n",
    "\n",
    "# calculate the cosine similarity between word pair, \n",
    "# if a word not in the embedding, \n",
    "# the similarity will be replaced by the similarity measured by human \n",
    "words = embeddings.keys()\n",
    "cos_sim = []\n",
    "for i in range(pairlen):\n",
    "    if word1[i] in words and word2[i] in words:\n",
    "        a = embeddings[word1[i]]\n",
    "        b = embeddings[word2[i]]\n",
    "        # calculate cosin similarity\n",
    "        cos_sim.append(np.inner(a,b)/(norm(a)*norm(b)))\n",
    "    else:\n",
    "        cos_sim.append(sim_human[i]/10) #divid 10 to change it into value in [0,1]\n",
    "\n",
    "# add a cloumn cosine similarity sorted the table according to it\n",
    "df = df_sim353.copy(deep=True)\n",
    "df['cos_sim']= cos_sim\n",
    "df_cos_sorted = df.sort_values(by=['cos_sim'],ascending=False)\n",
    "rank = range(1,pairlen+1)\n",
    "df_cos_sorted['rank (cos.sim.)'] = rank\n",
    "display(df_cos_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Rank the word pairs based on the similarity values as determined by humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Human (mean)</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>rank (human)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>fuck</td>\n",
       "      <td>sex</td>\n",
       "      <td>9.44</td>\n",
       "      <td>0.670561</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>midday</td>\n",
       "      <td>noon</td>\n",
       "      <td>9.29</td>\n",
       "      <td>0.665748</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>journey</td>\n",
       "      <td>voyage</td>\n",
       "      <td>9.29</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>dollar</td>\n",
       "      <td>buck</td>\n",
       "      <td>9.22</td>\n",
       "      <td>0.426276</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>money</td>\n",
       "      <td>cash</td>\n",
       "      <td>9.15</td>\n",
       "      <td>0.815317</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>coast</td>\n",
       "      <td>shore</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0.677802</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>money</td>\n",
       "      <td>cash</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.815317</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>money</td>\n",
       "      <td>currency</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.522259</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>football</td>\n",
       "      <td>soccer</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.814274</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>magician</td>\n",
       "      <td>wizard</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.513534</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>type</td>\n",
       "      <td>kind</td>\n",
       "      <td>8.97</td>\n",
       "      <td>0.679077</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>gem</td>\n",
       "      <td>jewel</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.578007</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>car</td>\n",
       "      <td>automobile</td>\n",
       "      <td>8.94</td>\n",
       "      <td>0.733075</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>street</td>\n",
       "      <td>avenue</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0.708214</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>asylum</td>\n",
       "      <td>madhouse</td>\n",
       "      <td>8.87</td>\n",
       "      <td>0.199657</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>boy</td>\n",
       "      <td>lad</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.531423</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>environment</td>\n",
       "      <td>ecology</td>\n",
       "      <td>8.81</td>\n",
       "      <td>0.535516</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>furnace</td>\n",
       "      <td>stove</td>\n",
       "      <td>8.79</td>\n",
       "      <td>0.585582</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>seafood</td>\n",
       "      <td>lobster</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.674077</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>mile</td>\n",
       "      <td>kilometer</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0.646130</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>king</td>\n",
       "      <td>queen</td>\n",
       "      <td>8.58</td>\n",
       "      <td>0.759618</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>murder</td>\n",
       "      <td>manslaughter</td>\n",
       "      <td>8.53</td>\n",
       "      <td>0.569898</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>money</td>\n",
       "      <td>bank</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.602752</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>computer</td>\n",
       "      <td>software</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.672374</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>vodka</td>\n",
       "      <td>gin</td>\n",
       "      <td>8.46</td>\n",
       "      <td>0.668546</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>planet</td>\n",
       "      <td>star</td>\n",
       "      <td>8.45</td>\n",
       "      <td>0.519998</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>calculation</td>\n",
       "      <td>computation</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0.669189</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>money</td>\n",
       "      <td>dollar</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0.614731</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>law</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.655002</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>cup</td>\n",
       "      <td>article</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.258458</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>sign</td>\n",
       "      <td>recess</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.206303</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>problem</td>\n",
       "      <td>airport</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.282557</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>reason</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>direction</td>\n",
       "      <td>combination</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.400209</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>cup</td>\n",
       "      <td>entity</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.095603</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>glass</td>\n",
       "      <td>magician</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.158012</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>cemetery</td>\n",
       "      <td>woodland</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.379716</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>possibility</td>\n",
       "      <td>girl</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.310412</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>cup</td>\n",
       "      <td>substance</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.190121</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>forest</td>\n",
       "      <td>graveyard</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.298963</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>energy</td>\n",
       "      <td>secretary</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.340388</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>month</td>\n",
       "      <td>hotel</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.333641</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>stock</td>\n",
       "      <td>egg</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.339092</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>precedent</td>\n",
       "      <td>group</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.122940</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>production</td>\n",
       "      <td>hike</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.183246</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stock</td>\n",
       "      <td>phone</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.306102</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>holy</td>\n",
       "      <td>sex</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.266039</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>drink</td>\n",
       "      <td>ear</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.270334</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>delay</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.171557</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>lad</td>\n",
       "      <td>wizard</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.207744</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>stock</td>\n",
       "      <td>life</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.411336</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>monk</td>\n",
       "      <td>slave</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.160540</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>stock</td>\n",
       "      <td>jaguar</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.276747</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>sugar</td>\n",
       "      <td>approach</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.249256</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>rooster</td>\n",
       "      <td>voyage</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.038883</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>noon</td>\n",
       "      <td>string</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.122765</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>chord</td>\n",
       "      <td>smile</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.181856</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>professor</td>\n",
       "      <td>cucumber</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.088859</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>king</td>\n",
       "      <td>cabbage</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.182654</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word 1        Word 2  Human (mean)   cos_sim  rank (human)\n",
       "2          tiger         tiger         10.00  1.000000             1\n",
       "37          fuck           sex          9.44  0.670561             2\n",
       "66        midday          noon          9.29  0.665748             3\n",
       "61       journey        voyage          9.29  0.643200             4\n",
       "249       dollar          buck          9.22  0.426276             5\n",
       "30         money          cash          9.15  0.815317             6\n",
       "63         coast         shore          9.10  0.677802             7\n",
       "90         money          cash          9.08  0.815317             8\n",
       "91         money      currency          9.04  0.522259             9\n",
       "38      football        soccer          9.03  0.814274            10\n",
       "65      magician        wizard          9.02  0.513534            11\n",
       "220         type          kind          8.97  0.679077            12\n",
       "60           gem         jewel          8.96  0.578007            13\n",
       "59           car    automobile          8.94  0.733075            14\n",
       "229       street        avenue          8.88  0.708214            15\n",
       "64        asylum      madhouse          8.87  0.199657            16\n",
       "62           boy           lad          8.83  0.531423            17\n",
       "287  environment       ecology          8.81  0.535516            18\n",
       "67       furnace         stove          8.79  0.585582            19\n",
       "270      seafood       lobster          8.70  0.674077            20\n",
       "157         mile     kilometer          8.66  0.646130            21\n",
       "33          king         queen          8.58  0.759618            22\n",
       "291       murder  manslaughter          8.53  0.569898            23\n",
       "95         money          bank          8.50  0.602752            24\n",
       "252     computer      software          8.50  0.672374            25\n",
       "51         vodka           gin          8.46  0.668546            26\n",
       "119       planet          star          8.45  0.519998            27\n",
       "241  calculation   computation          8.44  0.669189            28\n",
       "89         money        dollar          8.42  0.614731            29\n",
       "42           law        lawyer          8.38  0.655002            30\n",
       "..           ...           ...           ...       ...           ...\n",
       "135          cup       article          2.40  0.258458           306\n",
       "156         sign        recess          2.38  0.206303           307\n",
       "211      problem       airport          2.38  0.282557           308\n",
       "192       reason  hypertension          2.31  0.210041           309\n",
       "227    direction   combination          2.25  0.400209           310\n",
       "138          cup        entity          2.15  0.095603           311\n",
       "86         glass      magician          2.08  0.158012           312\n",
       "77      cemetery      woodland          2.08  0.379716           313\n",
       "300  possibility          girl          1.94  0.310412           314\n",
       "141          cup     substance          1.92  0.190121           315\n",
       "80        forest     graveyard          1.85  0.298963           316\n",
       "145       energy     secretary          1.81  0.340388           317\n",
       "219        month         hotel          1.81  0.333641           318\n",
       "23         stock           egg          1.81  0.339092           319\n",
       "131    precedent         group          1.77  0.122940           320\n",
       "235   production          hike          1.75  0.183246           321\n",
       "21         stock         phone          1.62  0.306102           322\n",
       "36          holy           sex          1.62  0.266039           323\n",
       "54         drink           ear          1.31  0.270334           324\n",
       "171        delay        racism          1.19  0.171557           325\n",
       "84           lad        wizard          0.92  0.207744           326\n",
       "26         stock          life          0.92  0.411336           327\n",
       "82          monk         slave          0.92  0.160540           328\n",
       "22         stock        jaguar          0.92  0.276747           329\n",
       "308        sugar      approach          0.88  0.249256           330\n",
       "88       rooster        voyage          0.62  0.038883           331\n",
       "87          noon        string          0.54  0.122765           332\n",
       "85         chord         smile          0.54  0.181856           333\n",
       "31     professor      cucumber          0.31  0.088859           334\n",
       "32          king       cabbage          0.23  0.182654           335\n",
       "\n",
       "[335 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_sorted = df.sort_values(by=['Human (mean)'],ascending=False)\n",
    "\n",
    "df_human_sorted['rank (human)'] = rank\n",
    "df_human_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Calculate the spearman rank correlation between the two ranked list of word-pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.6450611570036899, pvalue=8.391971318047086e-41)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "df_cos = df_cos_sorted.sort_index()\n",
    "df_human = df_human_sorted.sort_index()\n",
    "data1 = df_human['rank (human)']\n",
    "data2 = df_cos['rank (cos.sim.)']\n",
    "spearmanr(data1, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification with CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a set of news articles which are to be labelled 1 or 0. The data is split into 3 groups (train/test/validation). Each group is further divided into 2 files which consists of the text(ending with \\_X.p) and the label (ending with \\_y.p) respectively. Each datapoint is a list of words and they are all accumulated in a list forming a list of lists. The label file is a list of labels (0/1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will design a character-level CNN. So the first task would be to obtain a one-hot encoding for the characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the vocabulary of caracters is provided for your reference.. \n",
    "vocabulary = list(\"\"\" abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'/\\|_@#$%ˆ&*˜‘+-=<>()[]{}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characterEncoding(vocabulary):\n",
    "    c2v = {} # dictionary with key as a character and one-hot encoding as value\n",
    "    # write your code snippet here..\n",
    "    return c2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode a sentence as a 2D matrix with each row representing the one-hot encoding of a character in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2tensor(sentence,c2v):\n",
    "    # write your code snippet here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a dataset class for feeding data to your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    # write your code snippet here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a model class with 2 layers of convolutions each followed by a ReLU unit. The model should have linear layer which maps to the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    # write your code snippet here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a train function which trains on the train dataset. You can use binary cross entropy as your loss function and Adam as your optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, epochs=5, batchsize=32, learning_rate=0.0001):\n",
    "    # write your code snippet here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a test function which takes the trained model and test dataset and outputs the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_datset, batchsize=32):\n",
    "    # write your code snippet here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting it altogether\n",
    "\n",
    "train_dataset = \n",
    "test_dataset = \n",
    "\n",
    "model = Classifier()\n",
    "\n",
    "train(model, train_datset)\n",
    "test(model, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
